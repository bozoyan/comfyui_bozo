import torch
import numpy as np
from PIL import Image
import base64
import json
import os
from volcenginesdkarkruntime import Ark
from io import BytesIO
import requests

# è·å–å½“å‰æ–‡ä»¶æ‰€åœ¨ç›®å½•
current_dir = os.path.dirname(__file__)
# æ„å»º config.json çš„å®Œæ•´è·¯å¾„
config_path = os.path.join(current_dir, 'key/Volcengine.json')

# åŠ è½½é…ç½®æ–‡ä»¶
config = {}
if os.path.exists(config_path):
    try:
        with open(config_path, 'r', encoding='utf-8') as f:
            config = json.load(f)
    except Exception as e:
        print(f"ç«å±±æ–¹èˆŸå¯†é’¥é”™è¯¯: Error loading config.json: {e}")

# è·å–é»˜è®¤å€¼
DEFAULT_API_KEY = os.environ.get("ARK_API_KEY", config.get("api_key", "YOUR_ARK_API_KEY_HERE"))
DEFAULT_BASE_URL = config.get("base_url", "https://ark.cn-beijing.volces.com/api/v3")
DEFAULT_MODEL = config.get("model", "doubao-seedream-3-0-t2i-250415")
DEFAULT_MODEL_ID = config.get("model_id", "doubao-1-5-vision-pro-32k-250115")
DEFAULT_MODEL_EDIT = config.get("model_edit", "doubao-seededit-3-0-i2i-250628")

def save_config(api_key=None, base_url=None, model=None, model_id=None, model_edit=None):
    """ä¿å­˜é…ç½®åˆ°æ–‡ä»¶"""
    config_dir = os.path.dirname(config_path)
    if not os.path.exists(config_dir):
        os.makedirs(config_dir)
    
    # æ›´æ–°é…ç½®å­—å…¸
    if api_key and api_key != "YOUR_ARK_API_KEY_HERE":
        config["api_key"] = api_key
    if base_url:
        config["base_url"] = base_url
    if model:
        config["model"] = model
    if model_id:
        config["model_id"] = model_id
    if model_edit:
        config["model_edit"] = model_edit
    
    # ä¿å­˜åˆ°æ–‡ä»¶
    try:
        with open(config_path, 'w', encoding='utf-8') as f:
            json.dump(config, f, ensure_ascii=False, indent=4)
    except Exception as e:
        print(f"ä¿å­˜é…ç½®æ–‡ä»¶æ—¶å‡ºé”™: {e}")

class B_KontextDuoImageAnalyzer:
    @classmethod
    def INPUT_TYPES(s):
        """
        å®šä¹‰èŠ‚ç‚¹çš„è¾“å…¥ç±»å‹å’Œæ§ä»¶ã€‚
        ç°åœ¨ä¼šä» config.json è¯»å–é»˜è®¤å€¼ã€‚
        """
        return {
            "required": {
                "image_a": ("IMAGE",),
                "image_b": ("IMAGE",),
                "api_key": ("STRING", {
                    "multiline": False,
                    "default": DEFAULT_API_KEY
                }),
                "model_id": ("STRING", {
                    "multiline": False,
                    "default": DEFAULT_MODEL_ID
                }),
                "base_url": ("STRING", {
                    "multiline": False,
                    "default": DEFAULT_BASE_URL
                }),
                "prompt": ("STRING", {
                    "multiline": True,
                    "default": "è¯·å¯¹æ¯”åˆ†æè¿™ä¸¤å¼ å›¾ç‰‡ï¼Œæ€»ç»“å®ƒä»¬ä¹‹é—´çš„æ ¸å¿ƒå·®å¼‚å’Œå…±åŒç‚¹ã€‚"
                }),
            },
        }

    RETURN_TYPES = ("STRING",)
    RETURN_NAMES = ("analysis_text",)
    FUNCTION = "analyze"
    CATEGORY = "ğŸ‡¨ğŸ‡³BOZO/JM"

    def tensor_to_pil(self, tensor: torch.Tensor) -> Image.Image:
        """
        å°† ComfyUI çš„å›¾åƒå¼ é‡ (Tensor) è½¬æ¢ä¸º PIL Image å¯¹è±¡ã€‚
        æ˜ç¡®å¤„ç†æ‰¹å¤„ç†ï¼Œåªå–ç¬¬ä¸€å¼ å›¾ã€‚
        """
        # å–å‡ºæ‰¹æ¬¡ä¸­çš„ç¬¬ä¸€å¼ å›¾ï¼Œå¹¶ä» [0,1] èŒƒå›´è½¬æ¢ä¸º [0,255] èŒƒå›´
        image_np = tensor[0].cpu().numpy() * 255.0
        image_np = np.clip(image_np, 0, 255).astype(np.uint8)

        # ä» Numpy æ•°ç»„åˆ›å»º PIL Image
        return Image.fromarray(image_np)

    def pil_to_base64(self, pil_image: Image.Image) -> str:
        """
        å°† PIL Image å¯¹è±¡ç¼–ç ä¸º Base64 å­—ç¬¦ä¸²ã€‚
        """
        buffered = BytesIO()
        pil_image.save(buffered, format="PNG")
        return base64.b64encode(buffered.getvalue()).decode('utf-8')

    def analyze(self, image_a, image_b, api_key, model_id, base_url, prompt):
        """
        æ ¸å¿ƒåˆ†æå‡½æ•° - ä½¿ç”¨æ–°çš„ Ark SDK å¹¶å¢åŠ å¥å£®æ€§æ£€æŸ¥ã€‚
        """
        if not api_key or "YOUR_ARK_API_KEY_HERE" in api_key:
            return ("é”™è¯¯ï¼šè¯·è¾“å…¥æœ‰æ•ˆçš„ API Keyï¼Œæ‚¨å¯ä»¥åœ¨èŠ‚ç‚¹çš„è¾“å…¥æ¡†ä¸­æˆ–åœ¨ config.json æ–‡ä»¶ä¸­æä¾›ã€‚",)
        
        if not base_url:
            return ("é”™è¯¯ï¼šè¯·è¾“å…¥æœ‰æ•ˆçš„ Base URLã€‚",)
        
        # ä¿å­˜é…ç½®
        save_config(api_key=api_key, base_url=base_url, model_id=model_id)

        try:
            # 1. å°†è¾“å…¥çš„å¼ é‡è½¬æ¢ä¸º PIL å›¾åƒ
            pil_a = self.tensor_to_pil(image_a)
            pil_b = self.tensor_to_pil(image_b)

            # 2. å°† PIL å›¾åƒç¼–ç ä¸º Base64
            base64_a = self.pil_to_base64(pil_a)
            base64_b = self.pil_to_base64(pil_b)

            # 3. åˆå§‹åŒ– Ark å®¢æˆ·ç«¯
            client = Ark(api_key=api_key, base_url=base_url)

            # 4. å‘é€è¯·æ±‚
            response = client.chat.completions.create(
                model=model_id,
                messages=[
                    {
                        "role": "user",
                        "content": [
                            {"type": "text", "text": prompt},
                            {
                                "type": "image_url",
                                "image_url": {"url": f"data:image/png;base64,{base64_a}"}
                            },
                            {
                                "type": "image_url",
                                "image_url": {"url": f"data:image/png;base64,{base64_b}"}
                            },
                        ],
                    }
                ],
            )

            # 5. å®‰å…¨åœ°æå–ç»“æœ
            if response.choices and len(response.choices) > 0:
                result_text = response.choices[0].message.content
                return (result_text,)
            else:
                return ("é”™è¯¯ï¼šAPI è¿”å›äº†ç©ºçš„å“åº”ã€‚",)

        except Exception as e:
            # è¿”å›è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯
            error_message = f"Kontext Analyze: åˆ†ææ—¶å‡ºç°é”™è¯¯: {str(e)}"
            print(error_message) # åœ¨æ§åˆ¶å°ä¹Ÿæ‰“å°é”™è¯¯ï¼Œæ–¹ä¾¿è°ƒè¯•
            return (error_message,)

class B_DoubaoImageGenerator:
    @classmethod
    def INPUT_TYPES(s):
        """
        å®šä¹‰è±†åŒ…ç”Ÿå›¾èŠ‚ç‚¹çš„è¾“å…¥ç±»å‹å’Œæ§ä»¶ã€‚
        ä» config.json è¯»å–é»˜è®¤å€¼ã€‚
        """
        return {
            "required": {
                "prompt": ("STRING", {
                    "multiline": True,
                    "default": "ä¸€åªå¯çˆ±çš„å°çŒ«ï¼Œååœ¨èŠ±å›­é‡Œ"
                }),
                "api_key": ("STRING", {
                    "multiline": False,
                    "default": DEFAULT_API_KEY
                }),
                "model": ("STRING", {
                    "multiline": False,
                    "default": DEFAULT_MODEL
                }),
                "base_url": ("STRING", {
                    "multiline": False,
                    "default": DEFAULT_BASE_URL
                }),
                "size_preset": (["è‡ªå®šä¹‰", "9:16", "16:9", "1:1"], {
                    "default": "9:16"
                }),
                "custom_width": ("INT", {
                    "default": 1536,
                    "min": 512,
                    "max": 4096,
                    "step": 64
                }),
                "custom_height": ("INT", {
                    "default": 2730,
                    "min": 512,
                    "max": 4096,
                    "step": 64
                }),
                "seed": ("INT", {
                    "default": -1,
                    "min": -1,
                    "max": 2147483647
                }),
                "guidance_scale": ("FLOAT", {
                    "default": 2.5,
                    "min": 1.0,
                    "max": 20.0,
                    "step": 0.1
                }),
            },
        }

    RETURN_TYPES = ("STRING", "INT", "INT", "IMAGE")
    RETURN_NAMES = ("è¿œç¨‹URL", "é«˜åº¦", "å®½åº¦", "å›¾åƒ")
    FUNCTION = "generate_image"
    CATEGORY = "ğŸ‡¨ğŸ‡³BOZO/JM"

    def get_size_from_preset(self, size_preset, custom_width, custom_height):
        """
        æ ¹æ®é¢„è®¾æˆ–è‡ªå®šä¹‰å€¼è·å–å°ºå¯¸
        """
        size_mapping = {
            "9:16": (1536, 2730),
            "16:9": (2730, 1536),
            "1:1": (2048, 2048),
        }
        
        if size_preset == "è‡ªå®šä¹‰":
            return custom_width, custom_height
        else:
            return size_mapping[size_preset]

    def url_to_tensor(self, image_url):
        """
        ä»URLä¸‹è½½å›¾ç‰‡å¹¶è½¬æ¢ä¸ºComfyUIå¯ç”¨çš„å›¾åƒå¼ é‡ (float32, [0,1], [1,H,W,3])
        """
        try:
            # ä¸‹è½½å›¾ç‰‡
            response = requests.get(image_url, timeout=30)
            response.raise_for_status()
            
            # è½¬æ¢ä¸ºPILå›¾åƒå¹¶ç¡®ä¿ä¸ºRGB
            pil_image = Image.open(BytesIO(response.content))
            if pil_image.mode != 'RGB':
                pil_image = pil_image.convert('RGB')
            
            # è½¬æ¢ä¸ºnumpyæ•°ç»„ float32 [0,1]
            image_np = np.array(pil_image).astype(np.float32) / 255.0  # H,W,3
            image_np = np.clip(image_np, 0.0, 1.0)
            
            # è½¬ä¸ºtensorå¹¶æ·»åŠ batchç»´åº¦ -> [1,H,W,3]
            image_tensor = torch.from_numpy(image_np).unsqueeze(0)
            
            return image_tensor
            
        except Exception as e:
            print(f"è±†åŒ…ç”Ÿå›¾: å›¾ç‰‡è½¬æ¢é”™è¯¯: {str(e)}")
            # è¿”å›ä¸€ä¸ªé»˜è®¤çš„é»‘è‰²å›¾åƒ (float32 [0,1])
            return torch.zeros(1, 512, 512, 3, dtype=torch.float32)

    def generate_image(self, prompt, api_key, model, base_url, size_preset, custom_width, custom_height, seed, guidance_scale):
        """
        è±†åŒ…ç”Ÿå›¾æ ¸å¿ƒå‡½æ•°
        """
        if not api_key or "YOUR_ARK_API_KEY_HERE" in api_key:
            return ("é”™è¯¯ï¼šè¯·è¾“å…¥æœ‰æ•ˆçš„ API Key", 0, 0, torch.zeros(1, 512, 512, 3, dtype=torch.float32))
        
        if not base_url:
            return ("é”™è¯¯ï¼šè¯·è¾“å…¥æœ‰æ•ˆçš„ Base URL", 0, 0, torch.zeros(1, 512, 512, 3, dtype=torch.float32))
        
        # ä¿å­˜é…ç½®
        save_config(api_key=api_key, base_url=base_url, model=model)

        try:
            # è·å–å°ºå¯¸
            width, height = self.get_size_from_preset(size_preset, custom_width, custom_height)
            
            # æ„å»ºAPIè¯·æ±‚URL
            url = f"{base_url}/images/generations"
            
            # è¯·æ±‚å¤´
            headers = {
                "Content-Type": "application/json",
                "Authorization": f"Bearer {api_key}"
            }
            
            # watermark å›ºå®šåœ¨åå°ä¸º False
            watermark = False
            
            # è¯·æ±‚ä½“
            data = {
                "model": model,
                "prompt": prompt,
                "response_format": "url",
                "size": f"{width}x{height}",
                "seed": seed,
                "guidance_scale": guidance_scale,
                "watermark": watermark
            }
            
            # å‘é€è¯·æ±‚
            response = requests.post(url, headers=headers, json=data, timeout=60)
            response.raise_for_status()
            
            # è§£æå“åº”
            response_data = response.json()
            doubaoimg = response_data["data"][0]["url"]
            
            # åœ¨ç»ˆç«¯æ˜¾ç¤ºå›¾ç‰‡URL
            print(f"è±†åŒ…ç”Ÿå›¾: ç”Ÿæˆçš„å›¾ç‰‡URL: {doubaoimg}")
            
            # è½¬æ¢ä¸ºå›¾åƒtensor (float32 [0,1])
            image_tensor = self.url_to_tensor(doubaoimg)
            
            return (doubaoimg, height, width, image_tensor)
            
        except Exception as e:
            error_message = f"è±†åŒ…ç”Ÿå›¾: ç”Ÿæˆå›¾ç‰‡æ—¶å‡ºç°é”™è¯¯: {str(e)}"
            print(error_message)
            return (error_message, 0, 0, torch.zeros(1, 512, 512, 3, dtype=torch.float32))


class B_DoubaoImageEdit:
    @classmethod
    def INPUT_TYPES(s):
        return {
            "required": {
                "prompt": ("STRING", {
                    "multiline": True,
                    "default": "æ”¹æˆçˆ±å¿ƒå½¢çŠ¶çš„æ³¡æ³¡"
                }),
                "api_key": ("STRING", {
                    "multiline": False,
                    "default": DEFAULT_API_KEY
                }),
                "model": ("STRING", {
                    "multiline": False,
                    "default": DEFAULT_MODEL_EDIT
                }),
                "base_url": ("STRING", {
                    "multiline": False,
                    "default": DEFAULT_BASE_URL
                }),
                "seed": ("INT", {
                    "default": -1,
                    "min": -1,
                    "max": 2147483647
                }),
                "guidance_scale": ("FLOAT", {
                    "default": 5.5,
                    "min": 1.0,
                    "max": 20.0,
                    "step": 0.1
                }),
            },
            "optional": {
                "image_url": ("STRING", {
                    "multiline": False,
                    "default": ""
                }),
                "image": ("IMAGE",),
            }
        }

    RETURN_TYPES = ("STRING", "IMAGE")
    RETURN_NAMES = ("è¿œç¨‹URL", "å›¾åƒ")
    FUNCTION = "edit_image"
    CATEGORY = "ğŸ‡¨ğŸ‡³BOZO/JM"

    def url_to_tensor(self, image_url: str):
        try:
            resp = requests.get(image_url, timeout=30)
            resp.raise_for_status()

            pil_image = Image.open(BytesIO(resp.content))
            if pil_image.mode != 'RGB':
                pil_image = pil_image.convert('RGB')

            img_np = np.array(pil_image).astype(np.float32) / 255.0
            img_np = np.clip(img_np, 0.0, 1.0)
            img_tensor = torch.from_numpy(img_np).unsqueeze(0)
            return img_tensor
        except Exception as e:
            print(f"è±†åŒ…æ”¹å›¾: å›¾ç‰‡ä¸‹è½½/è½¬æ¢é”™è¯¯: {str(e)}")
            return torch.zeros(1, 512, 512, 3, dtype=torch.float32)

    def tensor_to_pil(self, tensor: torch.Tensor) -> Image.Image:
        """
        å°† ComfyUI çš„å›¾åƒå¼ é‡ (Tensor) è½¬æ¢ä¸º PIL Image å¯¹è±¡ã€‚
        æ˜ç¡®å¤„ç†æ‰¹å¤„ç†ï¼Œåªå–ç¬¬ä¸€å¼ å›¾ã€‚
        """
        # å–å‡ºæ‰¹æ¬¡ä¸­çš„ç¬¬ä¸€å¼ å›¾ï¼Œå¹¶ä» [0,1] èŒƒå›´è½¬æ¢ä¸º [0,255] èŒƒå›´
        image_np = tensor[0].cpu().numpy() * 255.0
        image_np = np.clip(image_np, 0, 255).astype(np.uint8)

        # ä» Numpy æ•°ç»„åˆ›å»º PIL Image
        return Image.fromarray(image_np)

    def pil_to_base64(self, pil_image: Image.Image) -> str:
        """
        å°† PIL Image å¯¹è±¡ç¼–ç ä¸º Base64 å­—ç¬¦ä¸²ã€‚
        """
        buffered = BytesIO()
        pil_image.save(buffered, format="PNG")
        return base64.b64encode(buffered.getvalue()).decode('utf-8')

    def validate_image(self, pil_image: Image.Image) -> tuple[bool, str]:
        """
        éªŒè¯å›¾åƒæ˜¯å¦ç¬¦åˆè¦æ±‚
        """
        width, height = pil_image.size
        
        # æ£€æŸ¥å°ºå¯¸
        if width <= 14 or height <= 14:
            return False, "å›¾åƒå®½é«˜å¿…é¡»å¤§äº14px"
        
        # æ£€æŸ¥å®½é«˜æ¯”
        aspect_ratio = width / height
        if aspect_ratio <= 1/3 or aspect_ratio >= 3:
            return False, "å›¾åƒå®½é«˜æ¯”å¿…é¡»åœ¨(1/3, 3)èŒƒå›´å†…"
        
        return True, ""

    def edit_image(self, prompt, api_key, model, base_url, seed, guidance_scale, image_url="", image=None):
        if not api_key or "YOUR_ARK_API_KEY_HERE" in api_key:
            return ("é”™è¯¯ï¼šè¯·è¾“å…¥æœ‰æ•ˆçš„ API Key", torch.zeros(1, 512, 512, 3, dtype=torch.float32))
        if not base_url:
            return ("é”™è¯¯ï¼šè¯·è¾“å…¥æœ‰æ•ˆçš„ Base URL", torch.zeros(1, 512, 512, 3, dtype=torch.float32))
        
        # å¦‚æœæä¾›äº†å›¾åƒå¼ é‡ä½†æ²¡æœ‰URLï¼Œåˆ™å°†å›¾åƒè½¬æ¢ä¸ºbase64
        image_data = image_url  # é»˜è®¤ä½¿ç”¨URL
        if image is not None and not image_url:
            try:
                # å°†tensorè½¬æ¢ä¸ºPILå›¾åƒ
                pil_image = self.tensor_to_pil(image)
                
                # éªŒè¯å›¾åƒ
                is_valid, error_msg = self.validate_image(pil_image)
                if not is_valid:
                    return (f"é”™è¯¯ï¼š{error_msg}", torch.zeros(1, 512, 512, 3, dtype=torch.float32))
                
                # è½¬æ¢ä¸ºbase64
                image_base64 = self.pil_to_base64(pil_image)
                image_data = f"data:image/png;base64,{image_base64}"
            except Exception as e:
                err = f"è±†åŒ…æ”¹å›¾: å›¾åƒå¤„ç†é”™è¯¯: {str(e)}"
                print(err)
                return (err, torch.zeros(1, 512, 512, 3, dtype=torch.float32))
        elif not image_url:
            return ("é”™è¯¯ï¼šè¯·è¾“å…¥æœ‰æ•ˆçš„åŸå›¾URLæˆ–æä¾›å›¾åƒè¾“å…¥", torch.zeros(1, 512, 512, 3, dtype=torch.float32))
        
        # ä¿å­˜é…ç½®
        save_config(api_key=api_key, base_url=base_url, model_edit=model)

        try:
            client = Ark(api_key=api_key, base_url=base_url)

            result = client.images.generate(
                model=model,
                prompt=prompt,
                image=image_data,
                seed=seed,
                guidance_scale=guidance_scale,
                size="adaptive",
                watermark=False
            )

            # å…¼å®¹å±æ€§æˆ–å­—å…¸ä¸¤ç§è®¿é—®æ–¹å¼
            try:
                url = result.data[0].url
            except Exception:
                url = result["data"][0]["url"]

            print(f"è±†åŒ…æ”¹å›¾: ç”Ÿæˆçš„å›¾ç‰‡URL: {url}")
            image_tensor = self.url_to_tensor(url)
            return (url, image_tensor)
        except Exception as e:
            err = f"è±†åŒ…æ”¹å›¾: ç”Ÿæˆå›¾ç‰‡æ—¶å‡ºç°é”™è¯¯: {str(e)}"
            print(err)
            return (err, torch.zeros(1, 512, 512, 3, dtype=torch.float32))