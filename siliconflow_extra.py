import os
import json
import base64
import requests
import torch
from PIL import Image
from io import BytesIO
import urllib.request
from openai import OpenAI

class BOZO_SiliconFlow_Base:
    """SiliconFlow APIåŸºç¡€ç±»ï¼Œæä¾›å…±äº«åŠŸèƒ½"""
    
    def __init__(self):
        """åˆå§‹åŒ–æ—¥å¿—ç³»ç»Ÿå’ŒAPIå¯†é’¥å­˜å‚¨"""
        self.log_messages = []  # å…¨å±€æ—¥å¿—æ¶ˆæ¯å­˜å‚¨
        # è·å–èŠ‚ç‚¹æ‰€åœ¨ç›®å½•
        self.node_dir = os.path.dirname(os.path.abspath(__file__))
        # æ„å»º key æ–‡ä»¶å¤¹è·¯å¾„
        key_folder = os.path.join(self.node_dir, 'key')
        if not os.path.exists(key_folder):
            os.makedirs(key_folder, exist_ok=True)
            self.log(f"åˆ›å»º key æ–‡ä»¶å¤¹: {key_folder}")
            
        self.key_file = os.path.join(key_folder, 'siliconflow_API_key.txt')
        if not os.path.exists(self.key_file):
            self.log(f"APIå¯†é’¥æ–‡ä»¶ä¸å­˜åœ¨: {self.key_file}")
            # åˆ›å»ºç©ºæ–‡ä»¶
            try:
                with open(self.key_file, 'w') as f:
                    f.write('')
                self.log("åˆ›å»ºäº†ç©ºçš„APIå¯†é’¥æ–‡ä»¶")
            except Exception as e:
                self.log(f"åˆ›å»ºAPIå¯†é’¥æ–‡ä»¶å¤±è´¥: {e}")
        
        # åŠ è½½ API å¯†é’¥
        self.api_key = self._load_api_key()
        
        # åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯
        if self.api_key:
            self.client = OpenAI(api_key=self.api_key, base_url="https://api.siliconflow.cn/v1")
        else:
            self.client = None
    
    def log(self, message):
        """æ·»åŠ æ—¥å¿—æ¶ˆæ¯"""
        print(message)
        self.log_messages.append(message)
    
    def _load_api_key(self):
        """ä»æ–‡ä»¶åŠ è½½APIå¯†é’¥"""
        try:
            if os.path.exists(self.key_file):
                with open(self.key_file, "r") as f:
                    key = f.read().strip()
                    if key:
                        self.log("æˆåŠŸåŠ è½½ API å¯†é’¥")
                    else:
                        self.log("è­¦å‘Š: API å¯†é’¥æ–‡ä»¶ä¸ºç©º")
                    return key
            else:
                self.log(f"è­¦å‘Š: API å¯†é’¥æ–‡ä»¶ä¸å­˜åœ¨: {self.key_file}")
                return ""
        except Exception as e:
            self.log(f"åŠ è½½ API å¯†é’¥æ—¶å‡ºé”™: {e}")
            return ""
    
    def _image_to_base64(self, image_tensor):
        """å°†å›¾åƒå¼ é‡è½¬æ¢ä¸ºbase64å­—ç¬¦ä¸²"""
        if image_tensor is None:
            return None
            
        # å–ç¬¬ä¸€å¸§å›¾åƒ
        if len(image_tensor.shape) == 4:
            image_tensor = image_tensor[0]
            
        # è½¬æ¢ä¸ºPILå›¾åƒ
        try:
            # å¯¹äº PyTorch Tensorï¼Œä½¿ç”¨ to æ–¹æ³•è½¬æ¢ç±»å‹
            if isinstance(image_tensor, torch.Tensor):
                # ç¡®ä¿å€¼åœ¨ 0-1 èŒƒå›´å†…
                if image_tensor.max() <= 1.0:
                    image_tensor = (image_tensor * 255).to(torch.uint8)
                else:
                    image_tensor = image_tensor.to(torch.uint8)
                
                # è½¬æ¢ä¸º numpy æ•°ç»„å†è½¬ä¸º PIL å›¾åƒ
                image = Image.fromarray(image_tensor.cpu().numpy())
            else:
                # å¯¹äº numpy æ•°ç»„ï¼Œä½¿ç”¨åŸæ¥çš„æ–¹æ³•
                image = Image.fromarray((image_tensor * 255).astype('uint8'))
            
            # è½¬æ¢ä¸ºbase64
            buffered = BytesIO()
            image.save(buffered, format="PNG")
            img_str = base64.b64encode(buffered.getvalue()).decode()
            return f"data:image/png;base64,{img_str}"
        except Exception as e:
            self.log(f"å›¾åƒè½¬æ¢ä¸ºbase64æ—¶å‡ºé”™: {e}")
            return None


class BOZO_SiliconFlow_LLM(BOZO_SiliconFlow_Base):
    """SiliconFlow LLMå¯¹è¯ç”Ÿæˆç±»"""
    
    INFO = "æ¨¡å‹åˆ—è¡¨ç½‘å€ï¼šhttps://cloud.siliconflow.cn/sft-cm1e5qhny00yiyfv6osmivkla/models"
    
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "system_prompt": ("STRING", {"default": "You are a helpful assistant.", "multiline": True}),
                "user_prompt": ("STRING", {"default": "è¯·ä»‹ç»ä¸€ä¸‹è‡ªå·±ã€‚", "multiline": True}),
                "model": ("STRING", {"default": "deepseek-ai/DeepSeek-V3"}),
                "temperature": ("FLOAT", {"default": 0.7, "min": 0.0, "max": 2.0, "step": 0.1}),
                "max_tokens": ("INT", {"default": 1024, "min": 1, "max": 4096}),
            },
            "optional": {
                "info": ("STRING", {
                    "default": "æ¨¡å‹åˆ—è¡¨ç½‘å€ï¼šhttps://cloud.siliconflow.cn/sft-cm1e5qhny00yiyfv6osmivkla/models",
                    "multiline": True,
                    "read_only": True
                })
            }
        }
    
    RETURN_TYPES = ("STRING", "STRING")
    RETURN_NAMES = ("response", "status")
    FUNCTION = "generate"
    CATEGORY = "ğŸ‡¨ğŸ‡³BOZO/X"
    
    def generate(self, system_prompt, user_prompt, model, temperature, max_tokens, **kwargs):
        """ç”ŸæˆLLMå¯¹è¯"""
        if not self.api_key:
            self.log("é”™è¯¯: æœªæ‰¾åˆ°APIå¯†é’¥ï¼Œè¯·åœ¨keyæ–‡ä»¶å¤¹ä¸­çš„siliconflow_API_key.txtæ–‡ä»¶ä¸­æ·»åŠ æœ‰æ•ˆçš„APIå¯†é’¥")
            return "", "é”™è¯¯: æœªæ‰¾åˆ°APIå¯†é’¥"
        
        try:
            self.log(f"ä½¿ç”¨æ¨¡å‹: {model}")
            self.log(f"ç³»ç»Ÿæç¤º: {system_prompt[:50]}...")
            self.log(f"ç”¨æˆ·æç¤º: {user_prompt[:50]}...")
            
            response = self.client.chat.completions.create(
                model=model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                temperature=temperature,
                max_tokens=max_tokens
            )
            
            result = response.choices[0].message.content
            self.log(f"ç”ŸæˆæˆåŠŸï¼Œå“åº”é•¿åº¦: {len(result)}")
            
            return result, "æˆåŠŸ"
            
        except Exception as e:
            error_msg = f"ç”Ÿæˆå¯¹è¯æ—¶å‡ºé”™: {str(e)}"
            self.log(error_msg)
            return "", error_msg


class BOZO_SiliconFlow_ImageAnalysis(BOZO_SiliconFlow_Base):
    """SiliconFlow å›¾åƒåˆ†æç±»"""
    
    INFO = "æ¨¡å‹åˆ—è¡¨ç½‘å€ï¼šhttps://cloud.siliconflow.cn/sft-cm1e5qhny00yiyfv6osmivkla/models"
    
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "image": ("IMAGE",),
                "prompt": ("STRING", {"default": "åˆ†åˆ«é€šè¿‡ä¸­æ–‡è¯­è¨€å’Œè‹±æ–‡è¯­è¨€è¯¦ç»†æè¿°è¿™å¼ å›¾ç‰‡ä¸­çš„å†…å®¹ã€‚ä¸­æ–‡æè¿°ç”¨ã€Šã€‹å°†ä¸­æ–‡æ•°æ®åŒ…å«ï¼Œè‹±æ–‡æè¿°ç”¨ã€ã€‘å°†è‹±æ–‡æ•°æ®åŒ…å«ã€‚", "multiline": True}),
                "model": ("STRING", {"default": "THUDM/GLM-4.1V-9B-Thinking"}),
                "temperature": ("FLOAT", {"default": 0.7, "min": 0.0, "max": 2.0, "step": 0.1}),
                "max_tokens": ("INT", {"default": 1024, "min": 1, "max": 4096}),
            },
            "optional": {
                "info": ("STRING", {
                    "default": "æ¨¡å‹åˆ—è¡¨ç½‘å€ï¼šhttps://cloud.siliconflow.cn/sft-cm1e5qhny00yiyfv6osmivkla/models",
                    "multiline": True,
                    "read_only": True
                })
            }
        }
    
    RETURN_TYPES = ("STRING", "STRING")
    RETURN_NAMES = ("ä¸­æ–‡åˆ†æ", "è‹±æ–‡åˆ†æ")
    FUNCTION = "analyze"
    CATEGORY = "ğŸ‡¨ğŸ‡³BOZO/X"
    
    def analyze(self, image, prompt, model, temperature, max_tokens, **kwargs):
        """åˆ†æå›¾åƒå†…å®¹"""
        if not self.api_key:
            self.log("é”™è¯¯: æœªæ‰¾åˆ°APIå¯†é’¥ï¼Œè¯·åœ¨keyæ–‡ä»¶å¤¹ä¸­çš„siliconflow_API_key.txtæ–‡ä»¶ä¸­æ·»åŠ æœ‰æ•ˆçš„APIå¯†é’¥")
            return "é”™è¯¯: æœªæ‰¾åˆ°APIå¯†é’¥", "Error: API key not found"
        
        try:
            # å°†å›¾åƒè½¬æ¢ä¸ºbase64
            image_base64 = self._image_to_base64(image)
            if not image_base64:
                return "é”™è¯¯: å›¾åƒå¤„ç†å¤±è´¥", "Error: Image processing failed"
            
            self.log(f"åˆ†æå›¾åƒï¼Œä½¿ç”¨æ¨¡å‹: {model}ï¼Œæç¤º: {prompt[:50]}...")
            
            # å‘é€å•æ¬¡è¯·æ±‚ï¼Œè¦æ±‚åŒæ—¶ç”¨ä¸­è‹±æ–‡æè¿°
            combined_prompt = "è¯·åŒæ—¶ç”¨ä¸­æ–‡å’Œè‹±æ–‡è¯¦ç»†æè¿°è¿™å¼ å›¾ç‰‡çš„å†…å®¹ã€‚å…ˆç»™å‡ºä¸­æ–‡æè¿°ï¼Œç„¶åç»™å‡ºè‹±æ–‡æè¿°ã€‚" + prompt
            
            response = self.client.chat.completions.create(
                model=model,
                messages=[
                    {
                        "role": "user",
                        "content": [
                            {
                                "type": "image_url",
                                "image_url": {
                                    "url": image_base64
                                }
                            },
                            {
                                "type": "text",
                                "text": combined_prompt
                            }
                        ]
                    }
                ],
                temperature=temperature,
                max_tokens=max_tokens
            )
            
            result = response.choices[0].message.content
            self.log(f"å›¾åƒåˆ†ææˆåŠŸï¼Œå“åº”é•¿åº¦: {len(result)}")
            
            # æå–ä¸­æ–‡å’Œè‹±æ–‡åˆ†æç»“æœ
            cn_result = self._extract_chinese_analysis(result)
            en_result = self._extract_english_analysis(result)
            
            # åœ¨ç»ˆç«¯æ˜¾ç¤ºä¸­æ–‡å’Œè‹±æ–‡åˆ†æç»“æœï¼Œæ–¹ä¾¿æ’æŸ¥
            self.log("=" * 50)
            self.log("ä¸­æ–‡åˆ†æç»“æœ:")
            self.log("-" * 50)
            # é™åˆ¶è¾“å‡ºé•¿åº¦ï¼Œé¿å…æ—¥å¿—è¿‡é•¿
            cn_preview = cn_result[:500] + "..." if len(cn_result) > 500 else cn_result
            self.log(cn_preview)
            self.log("-" * 50)
            self.log("è‹±æ–‡åˆ†æç»“æœ:")
            self.log("-" * 50)
            en_preview = en_result[:500] + "..." if len(en_result) > 500 else en_result
            self.log(en_preview)
            self.log("=" * 50)
            
            return cn_result, en_result
            
        except Exception as e:
            error_msg = f"åˆ†æå›¾åƒæ—¶å‡ºé”™: {str(e)}"
            self.log(error_msg)
            return f"é”™è¯¯: {error_msg}", f"Error: {error_msg}"
    
    def _extract_chinese_analysis(self, text):
        """ä»ã€Šã€‹ä¸­æå–ä¸­æ–‡åˆ†æç»“æœ"""
        import re
        match = re.search(r'ã€Š(.*?)ã€‹', text, re.DOTALL)
        if match:
            return match.group(1).strip()
        return "æœªæ‰¾åˆ°ã€Šã€‹å†…çš„ä¸­æ–‡åˆ†æå†…å®¹"
    
    def _extract_english_analysis(self, text):
        """ä»ã€ã€‘ä¸­æå–è‹±æ–‡åˆ†æç»“æœ"""
        import re
        match = re.search(r'ã€(.*?)ã€‘', text, re.DOTALL)
        if match:
            return match.group(1).strip()
        return "Not found English analysis in ã€ã€‘"


class BOZO_SiliconFlow_JSONGenerator(BOZO_SiliconFlow_Base):
    """SiliconFlow JSONç”Ÿæˆç±»"""
    
    INFO = "æ¨¡å‹åˆ—è¡¨ç½‘å€ï¼šhttps://cloud.siliconflow.cn/sft-cm1e5qhny00yiyfv6osmivkla/models"
    
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "system_prompt": ("STRING", {"default": "æ‚¨æ˜¯ä¸€ä¸ªç¼–ç¨‹åŠ©æ‰‹, æ—¨åœ¨è¾“å‡ºè‹±æ–‡JSONæ ¼å¼çš„æ–‡ä»¶ï¼Œjsonæ–‡ä»¶çš„ç¬¬ä¸€æ¡æ•°æ®ä¸ºåˆ†ç±»å­—æ®µçš„è§£é‡Šæ•°æ®ã€‚", "multiline": True}),
                "user_prompt": ("STRING", {"default": "ç”Ÿæˆä¸€ä¸ªåŒ…å«ä¸‰ä¸ªè™šæ„äººç‰©çš„JSONæ•°æ®ï¼Œæ¯ä¸ªäººç‰©åŒ…å«å§“åã€å¹´é¾„å’ŒèŒä¸šå­—æ®µã€‚", "multiline": True}),
                "model": ("STRING", {"default": "Qwen/Qwen3-Coder-30B-A3B-Instruct"}),
                "temperature": ("FLOAT", {"default": 0.7, "min": 0.0, "max": 2.0, "step": 0.1}),
                "max_tokens": ("INT", {"default": 1024, "min": 1, "max": 4096}),
            },
            "optional": {
                "info": ("STRING", {
                    "default": "æ¨¡å‹åˆ—è¡¨ç½‘å€ï¼šhttps://cloud.siliconflow.cn/sft-cm1e5qhny00yiyfv6osmivkla/models",
                    "multiline": True,
                    "read_only": True
                })
            }
        }
    
    RETURN_TYPES = ("STRING", "STRING")
    RETURN_NAMES = ("json_data", "status")
    FUNCTION = "generate_json"
    CATEGORY = "ğŸ‡¨ğŸ‡³BOZO/X"
    
    def generate_json(self, system_prompt, user_prompt, model, temperature, max_tokens, **kwargs):
        """ç”ŸæˆJSONæ•°æ®"""
        if not self.api_key:
            self.log("é”™è¯¯: æœªæ‰¾åˆ°APIå¯†é’¥ï¼Œè¯·åœ¨keyæ–‡ä»¶å¤¹ä¸­çš„siliconflow_API_key.txtæ–‡ä»¶ä¸­æ·»åŠ æœ‰æ•ˆçš„APIå¯†é’¥")
            return "", "é”™è¯¯: æœªæ‰¾åˆ°APIå¯†é’¥"
        
        try:
            self.log(f"ä½¿ç”¨æ¨¡å‹: {model}")
            self.log(f"ç³»ç»Ÿæç¤º: {system_prompt[:50]}...")
            self.log(f"ç”¨æˆ·æç¤º: {user_prompt[:50]}...")
            
            response = self.client.chat.completions.create(
                model=model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                temperature=temperature,
                max_tokens=max_tokens,
                response_format={"type": "json_object"}
            )
            
            result = response.choices[0].message.content
            
            # éªŒè¯JSONæ ¼å¼
            try:
                json_obj = json.loads(result)
                self.log(f"ç”ŸæˆæˆåŠŸï¼ŒJSONå¯¹è±¡åŒ…å« {len(json_obj)} ä¸ªé¡¶çº§é”®")
                return result, "æˆåŠŸ"
            except json.JSONDecodeError as e:
                self.log(f"è­¦å‘Š: ç”Ÿæˆçš„å†…å®¹ä¸æ˜¯æœ‰æ•ˆçš„JSON: {e}")
                return result, f"è­¦å‘Š: éæœ‰æ•ˆJSONæ ¼å¼ ({e})"
            
        except Exception as e:
            error_msg = f"ç”ŸæˆJSONæ—¶å‡ºé”™: {str(e)}"
            self.log(error_msg)
            return "", error_msg
