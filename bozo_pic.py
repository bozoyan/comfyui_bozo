import torch
import random
import comfy.model_management
import os
import time
import cv2
import numpy as np
from PIL import Image
import folder_paths
import json

# ğŸ¯BOZO è°ƒç”¨æ–‡æœ¬è¡Œæ•°æ®
class Bozo_SplitNode:
    CATEGORY = "ğŸ‡¨ğŸ‡³BOZO/JSON"
    RETURN_TYPES = ("STRING", "INT",)
    RETURN_NAMES = ("parsed_data", "array_size",)
    FUNCTION = "Split_json"

    def __init__(self):
        pass

    def Split_json(self, text_data, line_number):
        lines = text_data.splitlines()
        if 0 <= line_number < len(lines):
            return lines[line_number], len(lines)
        else:
            raise IndexError("Line number out of range")

    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "text_data": ("STRING", {"default": ""}),
                "line_number": ("INT", {"default": 0, "min": 0}),
            },
        }


# åˆ›å»ºä¸€ä¸ªç©ºçš„torch.Tensorå‘é‡ç©ºé—´ï¼Œä¹Ÿå«å™ªç‚¹å›¾ï¼Œå¹¶è¾“å‡ºã€‚åªéœ€è¦è¿æ¥æœ€åŸºç¡€çš„preview imageèŠ‚ç‚¹å°±èƒ½å±•ç¤ºå‡ºæ¥ã€‚
class Bozo_Pic:
    def __init__(self):
        pass
    CATEGORY = "ğŸ‡¨ğŸ‡³BOZO/PIC"

    @classmethod
    def INPUT_TYPES(s):
        return {
            "required": {
                "width": ("INT", {"default": 512, "min": 64, "max": 2200, "step": 128}),
                "height": ("INT", {"default": 512, "min": 64, "max": 2200, "step": 128}),
            },
        }

    OUTPUT_NODE = True
    RETURN_TYPES = ("IMAGE",)
    RETURN_NAMES = ("å›¾åƒè¾“å‡º",)


    FUNCTION = "test"
    def test(self,width,height,):
        # 1åŠ è½½æ¨¡å‹========================================================================
        # æ¸…ç©ºæ‰€æœ‰åŠ è½½æ¨¡å‹
        comfy.model_management.unload_all_models()
        # åŠ è½½æ¨¡å‹ç•¥è¿‡ï¼Œå› ä¸ºéœ€è¦å¼•å…¥é¢å¤–çš„åŒ…

        # 2è®¾ç½®å‚æ•°========================================================================
        # width
        # height

        seed = random.randint(0, 0xffffffffffffffff)  # éšæœºç”Ÿæˆç§å­intæ ¼å¼
        torch.manual_seed(seed)  # è®¾ç½®ç§å­

        # 3è¿›è¡Œæ¨ç†========================================================================
        # ä¿®æ­£å®½é«˜ä½ç½®ï¼šåº”è¯¥æ˜¯ (batch_size, channels, height, width)
        noise = torch.randn((1, 3, height, width), device="cpu")

        # 4æ•°æ®æ ¼å¼å¤„ç†=====================================================================
        # æ³¨é‡Šï¼šè¾“å‡ºå¾€å¾€æ˜¯ä¸€ä¸ªPIL.imageçš„æ•°æ®ç±»å‹ï¼Œéœ€è¦æŠŠå›¾ç‰‡æ•°æ®è½¬åŒ–æˆtorch.Tensoræ•°æ®ç±»å‹æ‰å¯ä»¥è¢«comfyuiä¸­çš„previeimageèŠ‚ç‚¹æ¥æ”¶

        # [PIL.Image.Image]->[torch.Tensor]
        # torch.Tensoråˆ—è¡¨ = [ToTensor()(img) for img in å›¾ç‰‡åˆ—è¡¨]

        # [torch.Tensor]->torch.Tensor
        # åˆå¹¶çš„torch.Tensor = torch.stack(torch.Tensoråˆ—è¡¨)

        # è°ƒæ•´ç»´åº¦é¡ºåº(2,3,1024,1024)->(2,1024,1024,3)
        # è°ƒæ•´é¡ºåºä¹‹åçš„tensor=è°ƒæ•´é¡ºåºä¹‹å‰çš„tensor.permute(0, 2, 3, 1).cpu()
        tensor=noise.permute(0, 2, 3, 1).cpu()

        # 5è¾“å‡º===========================================================================
        return (tensor,)

# ä½¿ç”¨modelscopeçš„GPENæ¨¡å‹è¿›è¡Œå›¾åƒå¢å¼º
class BOZO_GpenImage:
    def __init__(self):
        # ä¿®æ”¹è¾“å‡ºè·¯å¾„ä¸ºComfyUIæ ¹ç›®å½•ä¸‹çš„outputæ–‡ä»¶å¤¹
        # import folder_paths
        self.output_dir = os.path.join(folder_paths.get_output_directory(), 'gpen_enhanced')
        if not os.path.exists(self.output_dir):
            os.makedirs(self.output_dir, exist_ok=True)
        
        # åˆå§‹åŒ–æ—¶ä¸åŠ è½½æ¨¡å‹ï¼Œåœ¨å®é™…ä½¿ç”¨æ—¶æ‰åŠ è½½
        self.model = None
    
    CATEGORY = "ğŸ‡¨ğŸ‡³BOZO/PIC"

    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "image_url": ("STRING", {"default": "", "multiline": False, "label": "å›¾ç‰‡URLæˆ–æœ¬åœ°è·¯å¾„"}),
                "filename": ("STRING", {"default": "enhanced", "multiline": False, "label": "è¾“å‡ºæ–‡ä»¶å"}),
            },
        }

    RETURN_TYPES = ("IMAGE", "STRING",)
    RETURN_NAMES = ("å¢å¼ºå›¾åƒ", "å›¾åƒè·¯å¾„",)
    FUNCTION = "enhance_image"
    
    def enhance_image(self, image_url, filename):
        try:
            # æ¸…ç©ºæ‰€æœ‰åŠ è½½æ¨¡å‹
            comfy.model_management.unload_all_models()
            
            # åœ¨å‡½æ•°å†…éƒ¨å¯¼å…¥æ‰€éœ€åº“
            try:
                # import cv2
                from modelscope.pipelines import pipeline
                from modelscope.utils.constant import Tasks
                from modelscope.outputs import OutputKeys
            except ImportError as e:
                print(f"âŒ å¯¼å…¥modelscopeç›¸å…³åº“å¤±è´¥: {str(e)}")
                print("è¯·å®‰è£…å¿…è¦çš„ä¾èµ–: pip install modelscope opencv-python")
                empty_tensor = torch.zeros((1, 64, 64, 3))
                return (empty_tensor, f"é”™è¯¯: ç¼ºå°‘å¿…è¦çš„ä¾èµ–åº“ï¼Œè¯·å®‰è£…modelscopeå’Œopencv-python")
            
            # å»¶è¿ŸåŠ è½½æ¨¡å‹
            if self.model is None:
                print("ğŸ”„ é¦–æ¬¡åŠ è½½GPENå›¾åƒå¢å¼ºæ¨¡å‹...")
                self.model = pipeline(Tasks.image_portrait_enhancement, model='iic/cv_gpen_image-portrait-enhancement-hires')
                print("âœ… GPENæ¨¡å‹åŠ è½½å®Œæˆ")
            
            # å¤„ç†å›¾åƒ
            print(f"ğŸ–¼ï¸ æ­£åœ¨å¤„ç†å›¾åƒ: {image_url}")
            result = self.model(image_url)
            enhanced_img = result[OutputKeys.OUTPUT_IMG]
            
            # ç”Ÿæˆå¸¦æ—¶é—´æˆ³çš„æ–‡ä»¶å
            # import time
            timestamp = time.strftime("%m%d_%H%M%S")
            if not filename.endswith('.png'):
                filename = f"{filename}.png"
            output_filename = f"{os.path.splitext(filename)[0]}_{timestamp}.png"
            output_path = os.path.join(self.output_dir, output_filename)
            
            # ä¿å­˜å›¾åƒ
            cv2.imwrite(output_path, enhanced_img)
            print(f"âœ… å¢å¼ºå›¾åƒå·²ä¿å­˜: {output_path}")
            
            # å°†OpenCVå›¾åƒè½¬æ¢ä¸ºPILå›¾åƒï¼Œå†è½¬æ¢ä¸ºComfyUIå¯ç”¨çš„tensor
            # import numpy as np
            # from PIL import Image
            
            # OpenCVå›¾åƒæ˜¯BGRæ ¼å¼ï¼Œéœ€è¦è½¬æ¢ä¸ºRGB
            rgb_img = cv2.cvtColor(enhanced_img, cv2.COLOR_BGR2RGB)
            pil_image = Image.fromarray(rgb_img)
            
            # è½¬æ¢ä¸ºPyTorchå¼ é‡
            tensor = torch.from_numpy(np.array(pil_image).astype(np.float32) / 255.0)
            tensor = tensor.unsqueeze(0)  # æ·»åŠ æ‰¹æ¬¡ç»´åº¦
            
            return (tensor, output_path)
            
        except Exception as e:
            print(f"âŒ å›¾åƒå¢å¼ºè¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}")
            # è¿”å›ä¸€ä¸ªç©ºå›¾åƒå’Œé”™è¯¯ä¿¡æ¯
            empty_tensor = torch.zeros((1, 64, 64, 3))
            return (empty_tensor, f"é”™è¯¯: {str(e)}")


# ç›´é“¾å›¾ç‰‡ä½¿ç”¨modelscopeçš„GPENæ¨¡å‹è¿›è¡Œå›¾åƒå¢å¼º
class B_GpenImage:
    def __init__(self):
        # è¾“å‡ºè·¯å¾„ä¸ºComfyUIæ ¹ç›®å½•ä¸‹çš„outputæ–‡ä»¶å¤¹ä¸­çš„gpen_enhancedå­ç›®å½•
        self.output_dir = os.path.join(folder_paths.get_output_directory(), 'gpen_enhanced')
        if not os.path.exists(self.output_dir):
            os.makedirs(self.output_dir, exist_ok=True)
        
        # åˆå§‹åŒ–æ—¶ä¸åŠ è½½æ¨¡å‹ï¼Œåœ¨å®é™…ä½¿ç”¨æ—¶æ‰åŠ è½½
        self.model = None

    CATEGORY = "ğŸ‡¨ğŸ‡³BOZO/PIC"

    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "image": ("IMAGE",),  # æ¥æ”¶ ComfyUI å›¾åƒå¼ é‡
                "filename": ("STRING", {"default": "enhanced", "multiline": False, "label": "è¾“å‡ºæ–‡ä»¶å"}),
            },
        }

    RETURN_TYPES = ("IMAGE", "STRING",)
    RETURN_NAMES = ("å¢å¼ºå›¾åƒ", "å›¾åƒè·¯å¾„",)
    FUNCTION = "enhance_image"
    
    def enhance_image(self, image, filename):
        try:
            # å¸è½½æ‰€æœ‰æ¨¡å‹ä»¥èŠ‚çœæ˜¾å­˜
            comfy.model_management.unload_all_models()

            # å¯¼å…¥ä¾èµ–
            try:
                from modelscope.pipelines import pipeline
                from modelscope.utils.constant import Tasks
                from modelscope.outputs import OutputKeys
            except ImportError as e:
                print(f"âŒ å¯¼å…¥modelscopeç›¸å…³åº“å¤±è´¥: {str(e)}")
                print("è¯·å®‰è£…å¿…è¦çš„ä¾èµ–: pip install modelscope opencv-python")
                empty_tensor = torch.zeros((1, 64, 64, 3))
                return (empty_tensor, f"é”™è¯¯: ç¼ºå°‘å¿…è¦çš„ä¾èµ–åº“ï¼Œè¯·å®‰è£…modelscopeå’Œopencv-python")

            # å»¶è¿ŸåŠ è½½æ¨¡å‹
            if self.model is None:
                print("ğŸ”„ é¦–æ¬¡åŠ è½½GPENå›¾åƒå¢å¼ºæ¨¡å‹...")
                self.model = pipeline(Tasks.image_portrait_enhancement, model='iic/cv_gpen_image-portrait-enhancement-hires')
                print("âœ… GPENæ¨¡å‹åŠ è½½å®Œæˆ")

            # å°† ComfyUI å›¾åƒå¼ é‡è½¬ä¸º PIL å›¾åƒ
            i = 255. * image.cpu().numpy()[0]
            img_np = np.clip(i, 0, 255).astype(np.uint8)
            pil_img = Image.fromarray(img_np)

            # è½¬æ¢ä¸º OpenCV æ ¼å¼ (BGR)
            open_cv_image = cv2.cvtColor(np.array(pil_img), cv2.COLOR_RGB2BGR)

            # ä¿å­˜ä¸´æ—¶å›¾åƒç”¨äºæ¨¡å‹å¤„ç†
            temp_input_path = os.path.join(self.output_dir, "temp_input.png")
            cv2.imwrite(temp_input_path, open_cv_image)

            # ä½¿ç”¨ ModelScope æ¨¡å‹è¿›è¡Œå¢å¼º
            result = self.model(temp_input_path)
            enhanced_img = result[OutputKeys.OUTPUT_IMG]

            # ç”Ÿæˆå¸¦æ—¶é—´æˆ³çš„æ–‡ä»¶å
            timestamp = time.strftime("%m%d_%H%M%S")
            if not filename.endswith('.png'):
                filename = f"{filename}.png"
            output_filename = f"{os.path.splitext(filename)[0]}_{timestamp}.png"
            output_path = os.path.join(self.output_dir, output_filename)

            # ä¿å­˜å¢å¼ºåçš„å›¾åƒ
            cv2.imwrite(output_path, enhanced_img)
            print(f"âœ… å¢å¼ºå›¾åƒå·²ä¿å­˜: {output_path}")

            # è½¬æ¢ä¸º RGB å¹¶è½¬ä¸º PyTorch Tensor
            rgb_img = cv2.cvtColor(enhanced_img, cv2.COLOR_BGR2RGB)
            pil_result = Image.fromarray(rgb_img)
            tensor_result = torch.from_numpy(np.array(pil_result).astype(np.float32) / 255.0).unsqueeze(0)

            return (tensor_result, output_path)

        except Exception as e:
            print(f"âŒ å›¾åƒå¢å¼ºè¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}")
            # è¿”å›ä¸€ä¸ªç©ºå›¾åƒå’Œé”™è¯¯ä¿¡æ¯
            empty_tensor = torch.zeros((1, 64, 64, 3))
            return (empty_tensor, f"é”™è¯¯: {str(e)}")

# æ–°å¢çš„æ‰¹é‡å›¾ç‰‡åŠ è½½ç±»
class Bozo_ImagesInput:
    def __init__(self):
        self.pic_json_dir = os.path.join(os.path.dirname(__file__), 'pic_json')
        if not os.path.exists(self.pic_json_dir):
            os.makedirs(self.pic_json_dir, exist_ok=True)

    CATEGORY = "ğŸ‡¨ğŸ‡³BOZO"

    @classmethod
    def INPUT_TYPES(cls):
        input_dir = folder_paths.get_input_directory()
        return {
            "required": {
                "mode": (["incremental_image"], {"default": "incremental_image"}),
                "seed": ("INT", {"default": 0, "min": 0, "max": 0xffffffffffffffff}),
                "randomize": ("BOOLEAN", {"default": False}),
                "index": ("INT", {"default": 0, "min": 0}),
                "label": ("STRING", {"default": "A"}),
                "path": ("STRING", {"default": input_dir}),
                "use_RGBA": ("BOOLEAN", {"default": False}),
                "filename_text_extension": ("BOOLEAN", {"default": True}),
            },
            "optional": {
                "clear_json": ("BOOLEAN", {"default": False}),  # å°†clear_jsonç§»è‡³optionalå¹¶è®¾ç½®é»˜è®¤å€¼
            }
        }

    RETURN_TYPES = ("IMAGE", "MASK", "STRING", "STRING")
    RETURN_NAMES = ("image", "mask", "filename_text", "all_data_json")
    FUNCTION = "load_images"
    
    def load_images(self, mode, seed, randomize, index, label, path, use_RGBA, filename_text_extension, clear_json=False):
        if not os.path.exists(path):
            raise ValueError(f"Path does not exist: {path}")
        
        # æ”¯æŒçš„å›¾ç‰‡æ ¼å¼
        supported_formats = ('.png', '.jpg', '.jpeg', '.bmp', '.webp', '.tiff')
        image_files = [f for f in os.listdir(path) if f.lower().endswith(supported_formats)]
        
        if not image_files:
            raise ValueError(f"No image files found in: {path}")
        
        # æ’åºæ–‡ä»¶åˆ—è¡¨
        image_files.sort()
        
        # å¤„ç†æ¸…ç©ºJSONæ•°æ®é€‰é¡¹
        json_filename = f"pic_data.json"
        json_path = os.path.join(self.pic_json_dir, json_filename)
        
        if clear_json and os.path.exists(json_path):
            os.remove(json_path)
        
        # è¯»å–ç°æœ‰çš„JSONæ•°æ®æˆ–åˆ›å»ºæ–°æ•°æ®
        if os.path.exists(json_path):
            with open(json_path, 'r', encoding='utf-8') as f:
                all_data = json.load(f)
        else:
            all_data = {
                "mode": mode,
                "label": label,
                "path": path,
                "total_images": len(image_files),
                "all_files": [],
                "current_index": -1  # æ·»åŠ å½“å‰ç´¢å¼•è·Ÿè¸ª
            }
        
        # æ·»åŠ æ‰€æœ‰æ–‡ä»¶çš„ç»å¯¹è·¯å¾„åˆ°all_filesåˆ—è¡¨ä¸­ï¼ˆå¦‚æœå°šæœªæ·»åŠ ï¼‰
        all_files_with_path = [os.path.join(path, f) for f in image_files]
        if not all_data["all_files"]:
            all_data["all_files"] = all_files_with_path
        elif set(all_data["all_files"]) != set(all_files_with_path):
            # å¦‚æœæ–‡ä»¶åˆ—è¡¨æœ‰å˜åŒ–ï¼Œæ›´æ–°æ–‡ä»¶åˆ—è¡¨
            all_data["all_files"] = all_files_with_path
            all_data["total_images"] = len(image_files)
            # é‡ç½®ç´¢å¼•ä»¥é¿å…è¶Šç•Œ
            all_data["current_index"] = -1
        
        # æ ¹æ®æ¨¡å¼å¤„ç†æ–‡ä»¶åˆ—è¡¨
        if mode == "incremental_image":
            # ä½¿ç”¨ç§å­å’Œç´¢å¼•æ¥ç¡®å®šå½“å‰æ–‡ä»¶ï¼Œç¡®ä¿æ¯æ¬¡ä»»åŠ¡åŠ è½½ä¸åŒå›¾ç‰‡
            if randomize:
                random.seed(seed)
                current_index = random.randint(0, len(image_files) - 1)
            else:
                # ä½¿ç”¨ç´¢å¼•ç¡®ä¿æŒ‰é¡ºåºåŠ è½½
                # æ¯æ¬¡æ‰§è¡Œæ—¶é€’å¢ç´¢å¼•ï¼Œç¡®ä¿æ‰¹é‡æ‰§è¡Œæ—¶ä¾æ¬¡åŠ è½½ä¸åŒå›¾ç‰‡
                all_data["current_index"] = (all_data["current_index"] + 1) % len(all_data["all_files"])
                current_index = all_data["current_index"]
                
        # è·å–å½“å‰æ–‡ä»¶
        current_file = image_files[current_index]
        image_path = os.path.join(path, current_file)
        
        # æ›´æ–°å½“å‰æ–‡ä»¶ä¿¡æ¯
        all_data["current_file"] = image_path
        all_data["index"] = current_index
        
        # åŠ è½½å›¾åƒ
        img = Image.open(image_path)
        
        # å¤„ç†RGBA
        if use_RGBA and img.mode != 'RGBA':
            img = img.convert('RGBA')
        elif not use_RGBA:
            img = img.convert('RGB')
        
        # è½¬æ¢ä¸ºtensor
        img_np = np.array(img).astype(np.float32) / 255.0
        img_tensor = torch.from_numpy(img_np).unsqueeze(0)
        
        # åˆ›å»ºè’™ç‰ˆ
        if img.mode == 'RGBA':
            alpha_channel = np.array(img)[:, :, 3]
            mask = (alpha_channel > 0).astype(np.float32)
            # ä¿®æ”¹maskæ ¼å¼ï¼Œç¡®ä¿è¾“å‡ºä¸ºäºŒç»´æ•°ç»„(H, W)
            mask_tensor = torch.from_numpy(mask)
        else:
            # ä¿®æ”¹maskæ ¼å¼ï¼Œç¡®ä¿è¾“å‡ºä¸ºäºŒç»´æ•°ç»„(H, W)
            mask_tensor = torch.zeros((img.size[1], img.size[0]), dtype=torch.float32)
        
        # å¤„ç†æ–‡ä»¶å
        if filename_text_extension:
            filename_text = current_file
        else:
            filename_text = os.path.splitext(current_file)[0]
        
        # ä¿å­˜åˆ°pic_jsonç›®å½•
        with open(json_path, 'w', encoding='utf-8') as f:
            json.dump(all_data, f, ensure_ascii=False, indent=2)
        
        all_data_json = json.dumps(all_data, ensure_ascii=False)
        
        return (img_tensor, mask_tensor, filename_text, all_data_json)
