import torch
import random
import comfy.model_management
import os
# ç§»é™¤é¡¶éƒ¨çš„ modelscope ç›¸å…³å¯¼å…¥
# import cv2
# from modelscope.pipelines import pipeline
# from modelscope.utils.constant import Tasks
# from modelscope.outputs import OutputKeys

# ğŸ¯BOZO è°ƒç”¨æ–‡æœ¬è¡Œæ•°æ®
class Bozo_SplitNode:
    CATEGORY = "BOZO/JSON"
    RETURN_TYPES = ("STRING", "INT",)
    RETURN_NAMES = ("parsed_data", "array_size",)
    FUNCTION = "Split_json"

    def __init__(self):
        pass

    def Split_json(self, text_data, line_number):
        lines = text_data.splitlines()
        if 0 <= line_number < len(lines):
            return lines[line_number], len(lines)
        else:
            raise IndexError("Line number out of range")

    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "text_data": ("STRING", {"default": ""}),
                "line_number": ("INT", {"default": 0, "min": 0}),
            },
        }


# åˆ›å»ºä¸€ä¸ªç©ºçš„torch.Tensorå‘é‡ç©ºé—´ï¼Œä¹Ÿå«å™ªç‚¹å›¾ï¼Œå¹¶è¾“å‡ºã€‚åªéœ€è¦è¿æ¥æœ€åŸºç¡€çš„preview imageèŠ‚ç‚¹å°±èƒ½å±•ç¤ºå‡ºæ¥ã€‚
class Bozo_Pic:
    def __init__(self):
        pass
    CATEGORY = "BOZO/PIC"

    @classmethod
    def INPUT_TYPES(s):
        return {
            "required": {
                "width": ("INT", {"default": 512, "min": 64, "max": 2200, "step": 128}),
                "height": ("INT", {"default": 512, "min": 64, "max": 2200, "step": 128}),
            },
        }

    OUTPUT_NODE = True
    RETURN_TYPES = ("IMAGE",)
    RETURN_NAMES = ("å›¾åƒè¾“å‡º",)


    FUNCTION = "test"
    def test(self,width,height,):
        # 1åŠ è½½æ¨¡å‹========================================================================
        # æ¸…ç©ºæ‰€æœ‰åŠ è½½æ¨¡å‹
        comfy.model_management.unload_all_models()
        # åŠ è½½æ¨¡å‹ç•¥è¿‡ï¼Œå› ä¸ºéœ€è¦å¼•å…¥é¢å¤–çš„åŒ…

        # 2è®¾ç½®å‚æ•°========================================================================
        # width
        # height

        seed = random.randint(0, 0xffffffffffffffff)  # éšæœºç”Ÿæˆç§å­intæ ¼å¼
        torch.manual_seed(seed)  # è®¾ç½®ç§å­

        # 3è¿›è¡Œæ¨ç†========================================================================
        # ä¿®æ­£å®½é«˜ä½ç½®ï¼šåº”è¯¥æ˜¯ (batch_size, channels, height, width)
        noise = torch.randn((1, 3, height, width), device="cpu")

        # 4æ•°æ®æ ¼å¼å¤„ç†=====================================================================
        # æ³¨é‡Šï¼šè¾“å‡ºå¾€å¾€æ˜¯ä¸€ä¸ªPIL.imageçš„æ•°æ®ç±»å‹ï¼Œéœ€è¦æŠŠå›¾ç‰‡æ•°æ®è½¬åŒ–æˆtorch.Tensoræ•°æ®ç±»å‹æ‰å¯ä»¥è¢«comfyuiä¸­çš„previeimageèŠ‚ç‚¹æ¥æ”¶

        # [PIL.Image.Image]->[torch.Tensor]
        # torch.Tensoråˆ—è¡¨ = [ToTensor()(img) for img in å›¾ç‰‡åˆ—è¡¨]

        # [torch.Tensor]->torch.Tensor
        # åˆå¹¶çš„torch.Tensor = torch.stack(torch.Tensoråˆ—è¡¨)

        # è°ƒæ•´ç»´åº¦é¡ºåº(2,3,1024,1024)->(2,1024,1024,3)
        # è°ƒæ•´é¡ºåºä¹‹åçš„tensor=è°ƒæ•´é¡ºåºä¹‹å‰çš„tensor.permute(0, 2, 3, 1).cpu()
        tensor=noise.permute(0, 2, 3, 1).cpu()

        # 5è¾“å‡º===========================================================================
        return (tensor,)

# ä½¿ç”¨modelscopeçš„GPENæ¨¡å‹è¿›è¡Œå›¾åƒå¢å¼º
class BOZO_GpenImage:
    def __init__(self):
        # ä¿®æ”¹è¾“å‡ºè·¯å¾„ä¸ºComfyUIæ ¹ç›®å½•ä¸‹çš„outputæ–‡ä»¶å¤¹
        import folder_paths
        self.output_dir = os.path.join(folder_paths.get_output_directory(), 'gpen_enhanced')
        if not os.path.exists(self.output_dir):
            os.makedirs(self.output_dir, exist_ok=True)
        
        # åˆå§‹åŒ–æ—¶ä¸åŠ è½½æ¨¡å‹ï¼Œåœ¨å®é™…ä½¿ç”¨æ—¶æ‰åŠ è½½
        self.model = None
    
    CATEGORY = "BOZO/PIC"

    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "image_url": ("STRING", {"default": "", "multiline": False, "label": "å›¾ç‰‡URLæˆ–æœ¬åœ°è·¯å¾„"}),
                "filename": ("STRING", {"default": "enhanced", "multiline": False, "label": "è¾“å‡ºæ–‡ä»¶å"}),
            },
        }

    RETURN_TYPES = ("IMAGE", "STRING",)
    RETURN_NAMES = ("å¢å¼ºå›¾åƒ", "å›¾åƒè·¯å¾„",)
    FUNCTION = "enhance_image"
    
    def enhance_image(self, image_url, filename):
        try:
            # æ¸…ç©ºæ‰€æœ‰åŠ è½½æ¨¡å‹
            comfy.model_management.unload_all_models()
            
            # åœ¨å‡½æ•°å†…éƒ¨å¯¼å…¥æ‰€éœ€åº“
            try:
                import cv2
                from modelscope.pipelines import pipeline
                from modelscope.utils.constant import Tasks
                from modelscope.outputs import OutputKeys
            except ImportError as e:
                print(f"âŒ å¯¼å…¥modelscopeç›¸å…³åº“å¤±è´¥: {str(e)}")
                print("è¯·å®‰è£…å¿…è¦çš„ä¾èµ–: pip install modelscope opencv-python")
                empty_tensor = torch.zeros((1, 64, 64, 3))
                return (empty_tensor, f"é”™è¯¯: ç¼ºå°‘å¿…è¦çš„ä¾èµ–åº“ï¼Œè¯·å®‰è£…modelscopeå’Œopencv-python")
            
            # å»¶è¿ŸåŠ è½½æ¨¡å‹
            if self.model is None:
                print("ğŸ”„ é¦–æ¬¡åŠ è½½GPENå›¾åƒå¢å¼ºæ¨¡å‹...")
                self.model = pipeline(Tasks.image_portrait_enhancement, model='iic/cv_gpen_image-portrait-enhancement-hires')
                print("âœ… GPENæ¨¡å‹åŠ è½½å®Œæˆ")
            
            # å¤„ç†å›¾åƒ
            print(f"ğŸ–¼ï¸ æ­£åœ¨å¤„ç†å›¾åƒ: {image_url}")
            result = self.model(image_url)
            enhanced_img = result[OutputKeys.OUTPUT_IMG]
            
            # ç”Ÿæˆå¸¦æ—¶é—´æˆ³çš„æ–‡ä»¶å
            import time
            timestamp = time.strftime("%m%d_%H%M%S")
            if not filename.endswith('.png'):
                filename = f"{filename}.png"
            output_filename = f"{os.path.splitext(filename)[0]}_{timestamp}.png"
            output_path = os.path.join(self.output_dir, output_filename)
            
            # ä¿å­˜å›¾åƒ
            cv2.imwrite(output_path, enhanced_img)
            print(f"âœ… å¢å¼ºå›¾åƒå·²ä¿å­˜: {output_path}")
            
            # å°†OpenCVå›¾åƒè½¬æ¢ä¸ºPILå›¾åƒï¼Œå†è½¬æ¢ä¸ºComfyUIå¯ç”¨çš„tensor
            import numpy as np
            from PIL import Image
            
            # OpenCVå›¾åƒæ˜¯BGRæ ¼å¼ï¼Œéœ€è¦è½¬æ¢ä¸ºRGB
            rgb_img = cv2.cvtColor(enhanced_img, cv2.COLOR_BGR2RGB)
            pil_image = Image.fromarray(rgb_img)
            
            # è½¬æ¢ä¸ºPyTorchå¼ é‡
            tensor = torch.from_numpy(np.array(pil_image).astype(np.float32) / 255.0)
            tensor = tensor.unsqueeze(0)  # æ·»åŠ æ‰¹æ¬¡ç»´åº¦
            
            return (tensor, output_path)
            
        except Exception as e:
            print(f"âŒ å›¾åƒå¢å¼ºè¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}")
            # è¿”å›ä¸€ä¸ªç©ºå›¾åƒå’Œé”™è¯¯ä¿¡æ¯
            empty_tensor = torch.zeros((1, 64, 64, 3))
            return (empty_tensor, f"é”™è¯¯: {str(e)}")