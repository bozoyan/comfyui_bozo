# åœ¨æ–‡ä»¶é¡¶éƒ¨æ·»åŠ æ–°çš„å¯¼å…¥
import json
from PIL import Image, ImageOps
import os
import folder_paths
import numpy as np
import torch
import requests
from datetime import datetime
import urllib.parse
import os
import re
from openai import OpenAI
from io import BytesIO
import base64
import time

class ImagePathLoader:
    """åŠ è½½å›¾åƒå¹¶è·å–å…¶ç»å¯¹è·¯å¾„ï¼Œä¿å­˜ä¸º webp"""
    
    @classmethod
    def INPUT_TYPES(cls):
        input_dir = folder_paths.get_input_directory()
        files = [f for f in os.listdir(input_dir) if os.path.isfile(os.path.join(input_dir, f))]
        return {
            "required": {
                "image": (sorted(files), {"image_upload": True}),
                "use_url": ("BOOLEAN", {"default": False, "label": "ä½¿ç”¨ç½‘ç»œå›¾ç‰‡"}),
            },
            "optional": {
                "image_url": ("STRING", {"default": "", "multiline": False, "label": "å›¾ç‰‡URL"}),
            }
        }
    
    RETURN_TYPES = ("IMAGE", "STRING", "INT", "INT", "STRING", "IMAGE")
    RETURN_NAMES = ("image", "image_path", "width", "height", "base64_webp", "webp_image")
    FUNCTION = "load_image"
    CATEGORY = "ğŸ‡¨ğŸ‡³BOZO/PIC"

    def encode_image_b64(self, image):
        i = 255. * image.cpu().numpy()[0]
        img = Image.fromarray(np.clip(i, 0, 255).astype(np.uint8))

        lsize = np.max(img.size)
        factor = 1
        while lsize / factor > 2048:
            factor *= 2
        img = img.resize((img.size[0] // factor, img.size[1] // factor))

        image_path = f'{time.time()}.webp'
        img.save(image_path, 'WEBP')

        with open(image_path, "rb") as image_file:
            base64_image = base64.b64encode(image_file.read()).decode('utf-8')

        # print(img_base64)
        os.remove(image_path)
        return base64_image
    
    def download_image(self, url):
        try:
            # åˆ›å»ºè¾“å…¥ç›®å½•ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
            input_dir = folder_paths.get_input_directory()
            
            # åˆ›å»ºtempå­æ–‡ä»¶å¤¹
            temp_dir = os.path.join(input_dir, 'temp')
            os.makedirs(temp_dir, exist_ok=True)
            
            # ç”Ÿæˆå¸¦æ—¶é—´æˆ³çš„æ–‡ä»¶å
            timestamp = datetime.now().strftime('%m%d_%H%M%S')
            # ä»URLä¸­è·å–åŸå§‹æ–‡ä»¶æ‰©å±•å
            ext = os.path.splitext(urllib.parse.urlparse(url).path)[1]
            if not ext:
                ext = '.png'  # é»˜è®¤æ‰©å±•å
            filename = f"0_{timestamp}{ext}"
            filepath = os.path.join(temp_dir, filename)  # ä¿å­˜åˆ°tempå­æ–‡ä»¶å¤¹
            
            # ä¸‹è½½å›¾ç‰‡
            response = requests.get(url, timeout=10)
            response.raise_for_status()
            
            # ä¿å­˜å›¾ç‰‡
            with open(filepath, 'wb') as f:
                f.write(response.content)
            
            return filepath
            
        except Exception as e:
            print(f"ä¸‹è½½å›¾ç‰‡å¤±è´¥: {str(e)}")
            return None
    
    def load_image(self, image, use_url=False, image_url=""):
        try:
            if use_url and image_url:
                # ä¸‹è½½ç½‘ç»œå›¾ç‰‡
                image_path = self.download_image(image_url)
                if not image_path:
                    print("ä¸‹è½½å›¾ç‰‡å¤±è´¥")
                    return (None, "", 0, 0, "", None)
            else:
                # ä½¿ç”¨æœ¬åœ°å›¾ç‰‡
                image_path = folder_paths.get_annotated_filepath(image)
            
            if not os.path.exists(image_path):
                print(f"è­¦å‘Š: æ–‡ä»¶ä¸å­˜åœ¨ {image_path}")
                return (None, "", 0, 0, "", None)
            
            # åŠ è½½å›¾åƒ
            i = Image.open(image_path)
            i = ImageOps.exif_transpose(i)
            image = i.convert("RGB")
            image = np.array(image).astype(np.float32) / 255.0
            image = torch.from_numpy(image)[None,]
            
            # è·å–å›¾ç‰‡å°ºå¯¸
            width, height = i.size
            
            # ç”Ÿæˆbase64ç¼–ç çš„webpå›¾ç‰‡
            base64_webp = self.encode_image_b64(image)
            
            # åˆ›å»ºå¹¶ä¿å­˜webpå›¾åƒå¼ é‡åˆ°inputç›®å½•
            webp_image = image.clone()
            input_dir = folder_paths.get_input_directory()
            webp_filename = f"webp_output_{int(time.time())}.webp"
            webp_path = os.path.join(input_dir, webp_filename)
            
            # å°†å¼ é‡è½¬æ¢ä¸ºPILå›¾åƒå¹¶ä¿å­˜ä¸ºwebp
            i = 255. * webp_image.cpu().numpy()[0]
            img = Image.fromarray(np.clip(i, 0, 255).astype(np.uint8))
            img.save(webp_path, 'WEBP')
            
            # ä¿®æ”¹è¿”å›å€¼ï¼Œç¡®ä¿è¿”å›base64_webpæ•°æ®
            return (image, image_path, width, height, base64_webp, webp_image)
            
        except Exception as e:
            print(f"åŠ è½½å›¾åƒå¤±è´¥: {str(e)}")
            return (None, "", 0, 0, "", None)

class PNGInfoReader:
    """è¯»å– PNG å›¾ç‰‡ä¸­çš„å…ƒæ•°æ®ä¿¡æ¯"""
    
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "image_path": ("STRING", {"default": "", "multiline": False, "label": "å›¾ç‰‡è·¯å¾„"}),
            },
            "optional": {
                "as_json": ("BOOLEAN", {"default": True, "label": "è§£æä¸ºJSON"}),
            }
        }
    
    RETURN_TYPES = ("STRING", "STRING", "STRING", "STRING", "STRING", "STRING", "STRING", 
                   "STRING", "STRING", "STRING", "STRING", "STRING", "STRING", "STRING")
    RETURN_NAMES = ("metadata", "filename", "positive_prompt", "negative_prompt", "steps", "sampler", "cfg_scale", 
                   "clip_skip", "seed", "model", "lora_info", "vae", "hires_upscaler")
    FUNCTION = "read_pnginfo"
    CATEGORY = "ğŸ‡¨ğŸ‡³BOZO/PIC"
    
    def read_pnginfo(self, image_path="", as_json=True):
        try:
            if not image_path:
                empty_result = ("è¯·æä¾›å›¾ç‰‡è·¯å¾„",) * len(self.RETURN_TYPES)
                return empty_result
                
            if not os.path.exists(image_path):
                empty_result = (f"æ–‡ä»¶ä¸å­˜åœ¨: {image_path}",) * len(self.RETURN_TYPES)
                return empty_result
            
            # æ‰“å¼€å›¾ç‰‡å¹¶è¯»å–å…ƒæ•°æ®
            img = Image.open(image_path)
            metadata = None
            if "parameters" in img.info:
                metadata = img.info["parameters"]
            elif "Comment" in img.info:
                metadata = img.info["Comment"]
            
            if metadata is None:
                empty_result = (f"æœªæ‰¾åˆ°å…ƒæ•°æ®ä¿¡æ¯ã€‚æ–‡ä»¶è·¯å¾„: {image_path}",) * len(self.RETURN_TYPES)
                return empty_result

            # æå–æ–‡ä»¶å
            filename = os.path.splitext(os.path.basename(image_path))[0]
            
            # åˆ†æå…ƒæ•°æ®
            try:
                # æ£€æŸ¥æ˜¯å¦åŒ…å«è´Ÿå‘æç¤ºè¯
                if "Negative prompt:" in metadata:
                    parts = metadata.split("Negative prompt:")
                    positive_prompt = parts[0].strip()
                    remaining = parts[1]
                else:
                    # å¦‚æœæ²¡æœ‰è´Ÿå‘æç¤ºè¯ï¼Œç›´æ¥å¯»æ‰¾Steps
                    parts = metadata.split("Steps:")
                    positive_prompt = parts[0].strip()
                    remaining = "Steps:" + parts[1] if len(parts) > 1 else ""
                    negative_prompt = ""

                # å¦‚æœæœ‰è´Ÿå‘æç¤ºè¯ï¼Œç»§ç»­å¤„ç†
                if "Negative prompt:" in metadata:
                    neg_parts = remaining.split("Steps:")
                    negative_prompt = neg_parts[0].strip()
                    param_text = "Steps:" + neg_parts[1] if len(neg_parts) > 1 else ""
                else:
                    param_text = remaining

                # æå–å‚æ•°
                params = {}
                param_pairs = [p.strip() for p in param_text.split(",")]
                for pair in param_pairs:
                    if ":" in pair:
                        key, value = pair.split(":", 1)
                        params[key.strip()] = value.strip()

                # æ”¶é›†æ‰€æœ‰ Lora ç›¸å…³ä¿¡æ¯
                lora_info = []
                for key in params:
                    if key.startswith("Lora ") and "Hash" not in key and "Weight" not in key:
                        lora_num = key.split()[1]
                        lora_name = params.get(f"Lora {lora_num}", "")
                        lora_hash = params.get(f"Lora Hash {lora_num}", "")
                        lora_weight = params.get(f"Lora Weight {lora_num}", "")
                        if lora_name:
                            lora_info.append(f"Lora {lora_num}: {lora_name}")
                            if lora_hash:
                                lora_info.append(f"Hash: {lora_hash}")
                            if lora_weight:
                                lora_info.append(f"Weight: {lora_weight}")
                
                # æ£€æŸ¥æ˜¯å¦æœ‰ <lora:xxx> æ ¼å¼çš„ä¿¡æ¯
                for key in params:
                    if "<lora:" in key:
                        lora_info.append(key)

                # åˆå¹¶ Lora ä¿¡æ¯
                lora_info = ", ".join(lora_info) if lora_info else ""

                # æ ¼å¼åŒ–å…¶ä»–è¾“å‡º
                steps = params.get("Steps", "")
                sampler = params.get("Sampler", "")
                cfg_scale = params.get("CFG scale", "")
                clip_skip = params.get("Clip skip", "")
                seed = params.get("Seed", "")
                model = params.get("Model", "")
                vae = params.get("VAE", "") or params.get("vae_name", "")
                hires_upscaler = params.get("Hires upscaler", "")

                # å¦‚æœéœ€è¦ JSON æ ¼å¼
                if as_json:
                    metadata = json.dumps({
                        "file_path": image_path,
                        "metadata": metadata
                    }, ensure_ascii=False, indent=2)
                else:
                    metadata = f"æ–‡ä»¶è·¯å¾„: {image_path}\n\n{metadata}"

                return (metadata, filename, positive_prompt, negative_prompt, steps, sampler, 
                       cfg_scale, clip_skip, seed, model, lora_info, vae, hires_upscaler)

            except Exception as e:
                print(f"è§£æå…ƒæ•°æ®å¤±è´¥: {str(e)}")
                empty_result = (metadata,) + ("",) * (len(self.RETURN_TYPES) - 1)
                return empty_result

        except Exception as e:
            empty_result = (f"è¯»å– PNG å…ƒæ•°æ®å¤±è´¥: {str(e)}",) * len(self.RETURN_TYPES)
            return empty_result

class PNGInfoExtractor:
    """ä» PNG å…ƒæ•°æ®ä¸­æå–ç‰¹å®šä¿¡æ¯"""
    
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "metadata": ("STRING", {"default": "", "multiline": True}),
                "key": ("STRING", {"default": "prompt", "multiline": False}),
            }
        }
    
    RETURN_TYPES = ("STRING",)
    RETURN_NAMES = ("value",)
    FUNCTION = "extract_info"
    CATEGORY = "ğŸ‡¨ğŸ‡³BOZO/PIC"
    
    def extract_info(self, metadata, key):
        try:
            # å°è¯•è§£æä¸º JSON
            if metadata.startswith("{"):
                try:
                    data = json.loads(metadata)
                    if key in data:
                        value = data[key]
                        if isinstance(value, (dict, list)):
                            return (json.dumps(value, ensure_ascii=False, indent=2),)
                        return (str(value),)
                    return (f"æœªæ‰¾åˆ°é”®: {key}",)
                except:
                    pass
            
            # å¦‚æœä¸æ˜¯ JSONï¼Œå°è¯•ç®€å•è§£æ
            lines = metadata.split("\n")
            for line in lines:
                if line.startswith(key + ":"):
                    return (line[len(key)+1:].strip(),)
                elif line.startswith(key + "="):
                    return (line[len(key)+1:].strip(),)
            
            return (f"æœªæ‰¾åˆ°é”®: {key}",)
        except Exception as e:
            return (f"æå–ä¿¡æ¯å¤±è´¥: {str(e)}",)

class ImageJiexi:
    """ä½¿ç”¨ ModelScope API è§£æå›¾ç‰‡ç”Ÿæˆ prompt"""
    
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "image_url": ("STRING", {
                    "default": "", 
                    "multiline": False,
                    "label": "å›¾ç‰‡URL"
                }),
                "model": ("STRING", {
                    "default": "Qwen/Qwen2.5-VL-32B-Instruct",
                    "multiline": False,
                    "label": "æ¨¡å‹åç§°"
                }),
                "prompt_template": ("STRING", {
                    "default": "You are an AI art prompt expert. Upon receiving a provided image, you are capable of clearly, accurately and elaborately describing all key elements of the image in English. You can comprehensively provide English prompts regarding aspects such as the style, the subject, the scene, the details, and the color. Your prompts are capable of guiding StableDiffusion or Midjourney models to generate images that closely match the desired output. You only need to give a Prompt for AI Art Generation, no other Image Description and Prompt Analysis is required.Do not include the string 'plaintext' or 'prompt'.",
                    "multiline": True,
                    "label": "æç¤ºè¯æ¨¡æ¿"
                })
            }
        }
    
    RETURN_TYPES = ("STRING", "IMAGE",)
    RETURN_NAMES = ("prompt", "preview",)
    FUNCTION = "analyze_image"
    CATEGORY = "ğŸ‡¨ğŸ‡³BOZO/PIC"

    def analyze_image(self, image_url, model, prompt_template):
        try:
            # ä»æ–‡ä»¶è¯»å– API Token
            api_token = None
            # ä¿®æ”¹ API å¯†é’¥è·¯å¾„
            key_folder = os.path.join(os.path.dirname(__file__), 'key')
            if not os.path.exists(key_folder):
                os.makedirs(key_folder, exist_ok=True)
                print(f"åˆ›å»º key æ–‡ä»¶å¤¹: {key_folder}")
                
            api_key_path = os.path.join(key_folder, 'modelscope_api_key.txt')
            
            # æ£€æŸ¥ API key æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not os.path.exists(api_key_path):
                with open(api_key_path, 'w') as f:
                    f.write('')
                print(f"åˆ›å»ºç©ºçš„ API key æ–‡ä»¶: {api_key_path}")
                # åˆ›å»ºä¸€ä¸ªç©ºç™½å›¾åƒä½œä¸ºå¤‡ç”¨æ–¹æ¡ˆ
                blank_img = Image.new('RGB', (512, 512), color=(0, 0, 0))
                preview = np.array(blank_img).astype(np.float32) / 255.0
                preview = torch.from_numpy(preview)[None,]
                return ("é”™è¯¯: è¯·åœ¨ key/modelscope_api_key.txt ä¸­è®¾ç½®æœ‰æ•ˆçš„ API token", preview)
            
            try:
                with open(api_key_path, 'r') as f:
                    api_token = f.read().strip()
                    
                if not api_token:
                    # åˆ›å»ºä¸€ä¸ªç©ºç™½å›¾åƒä½œä¸ºå¤‡ç”¨æ–¹æ¡ˆ
                    blank_img = Image.new('RGB', (512, 512), color=(0, 0, 0))
                    preview = np.array(blank_img).astype(np.float32) / 255.0
                    preview = torch.from_numpy(preview)[None,]
                    return ("é”™è¯¯: key/modelscope_api_key.txt ä¸­æ²¡æœ‰æœ‰æ•ˆçš„ token", preview)
            except Exception as e:
                print(f"è¯»å– API key æ–‡ä»¶å¤±è´¥: {str(e)}")
                # åˆ›å»ºä¸€ä¸ªç©ºç™½å›¾åƒä½œä¸ºå¤‡ç”¨æ–¹æ¡ˆ
                blank_img = Image.new('RGB', (512, 512), color=(0, 0, 0))
                preview = np.array(blank_img).astype(np.float32) / 255.0
                preview = torch.from_numpy(preview)[None,]
                return ("é”™è¯¯: æ— æ³•ä» key/modelscope_api_key.txt è¯»å–æœ‰æ•ˆçš„ token", preview)

            # ä¸‹è½½å¹¶åŠ è½½é¢„è§ˆå›¾ç‰‡
            preview = None  # åˆå§‹åŒ–é¢„è§ˆä¸º None
            try:
                # ä¿®æ”¹ä¸ºä½¿ç”¨ output ç›®å½•ä¸‹çš„ temp æ–‡ä»¶å¤¹
                output_dir = folder_paths.get_output_directory()
                temp_dir = os.path.join(output_dir, 'temp')
                if not os.path.exists(temp_dir):
                    os.makedirs(temp_dir, exist_ok=True)
                    print(f"åˆ›å»ºä¸´æ—¶æ–‡ä»¶å¤¹: {temp_dir}")
                
                # ç”Ÿæˆå¸¦æ—¶é—´æˆ³çš„æ–‡ä»¶å
                timestamp = datetime.now().strftime('%m%d_%H%M%S')
                temp_image_path = os.path.join(temp_dir, f"preview_{timestamp}.png")
                
                # å¢å¼ºè¯·æ±‚å¤´ï¼Œæ¨¡æ‹Ÿæ›´çœŸå®çš„æµè§ˆå™¨è¡Œä¸º
                headers = {
                    'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
                    'Accept': 'image/avif,image/webp,image/apng,image/svg+xml,image/*,*/*;q=0.8',
                    'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
                    'Cache-Control': 'no-cache',
                    'Pragma': 'no-cache',
                    'sec-ch-ua': '"Not A(Brand";v="99", "Google Chrome";v="121", "Chromium";v="121"',
                    'sec-ch-ua-mobile': '?0',
                    'sec-ch-ua-platform': '"macOS"',
                    'Sec-Fetch-Dest': 'image',
                    'Sec-Fetch-Mode': 'no-cors',
                    'Sec-Fetch-Site': 'cross-site',
                }
                
                # æ·»åŠ åˆé€‚çš„ Referer
                parsed_url = urllib.parse.urlparse(image_url)
                base_url = f"{parsed_url.scheme}://{parsed_url.netloc}"
                headers['Referer'] = base_url
                
                # ç‰¹æ®Šå¤„ç† modelscope.cn åŸŸå
                if 'modelscope.cn' in image_url:
                    headers['Origin'] = 'https://www.modelscope.cn'
                    headers['Referer'] = 'https://www.modelscope.cn/'
                
                print(f"å°è¯•ä¸‹è½½å›¾ç‰‡: {image_url}")
                
                # ä½¿ç”¨ä¼šè¯å¯¹è±¡æ¥ä¿æŒ cookies
                session = requests.Session()
                response = session.get(image_url, headers=headers, timeout=15, allow_redirects=True)
                response.raise_for_status()
                
                # æ£€æŸ¥å†…å®¹ç±»å‹æ˜¯å¦ä¸ºå›¾ç‰‡
                content_type = response.headers.get('Content-Type', '')
                if not content_type.startswith('image/'):
                    print(f"è­¦å‘Š: å“åº”å†…å®¹ç±»å‹ä¸æ˜¯å›¾ç‰‡: {content_type}")
                
                # ä½¿ç”¨ PIL æ‰“å¼€å›¾ç‰‡ï¼ˆæ”¯æŒå¤šç§æ ¼å¼ï¼‰
                img = Image.open(BytesIO(response.content))
                
                # åº”ç”¨ EXIF æ—‹è½¬
                img = ImageOps.exif_transpose(img)
                
                # è½¬æ¢ä¸º RGB æ¨¡å¼ï¼ˆå¤„ç† RGBAã€ç°åº¦ç­‰å…¶ä»–æ¨¡å¼ï¼‰
                if img.mode != 'RGB':
                    img = img.convert('RGB')
                
                # ä¿å­˜ä¸º PNG æ ¼å¼ï¼Œä»¥ä¾¿å®˜æ–¹é¢„è§ˆèŠ‚ç‚¹å¯ä»¥ç›´æ¥ä½¿ç”¨
                img.save(temp_image_path, 'PNG')
                print(f"é¢„è§ˆå›¾ç‰‡å·²ä¿å­˜åˆ°: {temp_image_path}")
                
                # é‡æ–°åŠ è½½ä¿å­˜çš„å›¾ç‰‡ä»¥ç¡®ä¿æ ¼å¼ä¸€è‡´
                i = Image.open(temp_image_path)
                image = i.convert("RGB")
                preview = np.array(image).astype(np.float32) / 255.0
                preview = torch.from_numpy(preview)[None,]
                
            except requests.exceptions.HTTPError as e:
                print(f"HTTPé”™è¯¯: {e}")
                if e.response.status_code == 403:
                    print("æœåŠ¡å™¨æ‹’ç»è®¿é—®è¯¥å›¾ç‰‡ï¼Œå¯èƒ½éœ€è¦æˆæƒæˆ–è€…å›¾ç‰‡æœ‰è®¿é—®é™åˆ¶")
                    print("å°è¯•ä½¿ç”¨APIç›´æ¥å¤„ç†å›¾ç‰‡URLï¼Œè·³è¿‡é¢„è§ˆå›¾ç‰‡ä¸‹è½½...")
                    # åˆ›å»ºä¸€ä¸ªç©ºç™½å›¾åƒä½œä¸ºå¤‡ç”¨æ–¹æ¡ˆ
                    blank_img = Image.new('RGB', (512, 512), color=(200, 200, 200))
                    # åœ¨å›¾åƒä¸Šæ·»åŠ æ–‡æœ¬è¯´æ˜
                    from PIL import ImageDraw, ImageFont
                    draw = ImageDraw.Draw(blank_img)
                    try:
                        # å°è¯•åŠ è½½å­—ä½“ï¼Œå¦‚æœå¤±è´¥åˆ™ä½¿ç”¨é»˜è®¤å­—ä½“
                        font = ImageFont.truetype("Arial", 20)
                    except:
                        font = ImageFont.load_default()
                    draw.text((10, 10), "å›¾ç‰‡è®¿é—®å—é™ (403 Forbidden)", fill=(0, 0, 0), font=font)
                    draw.text((10, 40), "å°†ç›´æ¥ä½¿ç”¨URLè¿›è¡Œåˆ†æ", fill=(0, 0, 0), font=font)
                    preview = np.array(blank_img).astype(np.float32) / 255.0
                    preview = torch.from_numpy(preview)[None,]
                else:
                    # å…¶ä»–HTTPé”™è¯¯
                    blank_img = Image.new('RGB', (512, 512), color=(0, 0, 0))
                    preview = np.array(blank_img).astype(np.float32) / 255.0
                    preview = torch.from_numpy(preview)[None,]
            except Exception as e:
                print(f"ä¸‹è½½æˆ–å¤„ç†å›¾ç‰‡å¤±è´¥: {str(e)}")
                # åˆ›å»ºä¸€ä¸ªç©ºç™½å›¾åƒä½œä¸ºå¤‡ç”¨æ–¹æ¡ˆ
                blank_img = Image.new('RGB', (512, 512), color=(0, 0, 0))
                preview = np.array(blank_img).astype(np.float32) / 255.0
                preview = torch.from_numpy(preview)[None,]

            # åˆ›å»º API å®¢æˆ·ç«¯
            client = OpenAI(
                base_url='https://api-inference.modelscope.cn/v1/',
                api_key=api_token
            )
            
            # åˆ›å»ºè¯·æ±‚ï¼Œä½¿ç”¨åŸå§‹ URL ä½œä¸ºå›¾ç‰‡æº
            response = client.chat.completions.create(
                model=model,
                messages=[{
                    'role': 'user',
                    'content': [{
                        'type': 'text',
                        'text': prompt_template,
                    }, {
                        'type': 'image_url',
                        'image_url': {
                            'url': image_url
                        }
                    }]
                }],
                stream=False
            )

            # æ£€æŸ¥å“åº”æ˜¯å¦æœ‰æ•ˆ
            if not response or not hasattr(response, 'choices') or not response.choices:
                return ("API å“åº”æ— æ•ˆæˆ–ä¸ºç©º", preview)
                
            full_response = response.choices[0].message.content
            
            # ä¼˜åŒ–æå– prompt çš„é€»è¾‘
            pattern = r'["`]([^"`]*)["`]|```(.*?)```'
            matches = re.finditer(pattern, full_response, re.DOTALL)
            
            for match in matches:
                prompt = match.group(1) or match.group(2)
                if prompt:
                    # æ¸…ç†æç¤ºè¯ï¼Œç§»é™¤å¯èƒ½çš„å‰ç¼€æ–‡æœ¬
                    cleaned_prompt = prompt.strip()
                    # å¦‚æœæç¤ºè¯ä»¥å¸¸è§çš„å‰ç¼€å¼€å¤´ï¼Œåˆ™ç§»é™¤
                    prefixes = ['prompt:', 'promptï¼š', 'Prompt:', 'Promptï¼š']
                    for prefix in prefixes:
                        if cleaned_prompt.lower().startswith(prefix.lower()):
                            cleaned_prompt = cleaned_prompt[len(prefix):].strip()
                    
                    # ç§»é™¤ plaintextA å­—ç¬¦ä¸²
                    cleaned_prompt = cleaned_prompt.replace("plaintextA", "")
                    
                    return (cleaned_prompt.replace("\n", ""), preview)
            
            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°åŒ¹é…çš„æç¤ºè¯ï¼Œå°è¯•ç›´æ¥å¤„ç†å®Œæ•´å“åº”
            cleaned_response = full_response.replace("plaintextA", "")
            return (cleaned_response.replace("\n", " ").strip(), preview)

        except Exception as e:
            # ä¸ºé”™è¯¯æƒ…å†µåˆ›å»ºä¸€ä¸ªç©ºç™½å›¾åƒ
            blank_img = Image.new('RGB', (512, 512), color=(0, 0, 0))
            preview = np.array(blank_img).astype(np.float32) / 255.0
            preview = torch.from_numpy(preview)[None,]
            return (f"è§£æå›¾ç‰‡å¤±è´¥: {str(e)}", preview)
